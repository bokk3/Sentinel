# PROJECT_CONTEXT.md

## Project Overview

**Title (Working):** "I, Sentinel: Ethical Principles for Defensive AI" (or alternative from brainstormed list)

**Project Type:** Academic research paper on ethics and morals of AI in defensive systems and warfare

**Inspired By:** Isaac Asimov's Three Laws of Robotics aesthetic and framework

**Primary Goal:** Develop a rigorous, academically publishable ruleset/framework for the ethical deployment of AI in defensive military systems

---

## Core Research Questions

1. What ethical principles should govern AI use in defensive warfare systems?
2. How can we create actionable rules that balance military necessity with moral constraints?
3. What distinguishes defensive AI systems from offensive ones, and does this distinction matter ethically?
4. How do we address the accountability gap when machines make lethal decisions?
5. What mechanisms ensure compliance and verification of these ethical rules?

---

## Target Audience

**Primary:**

- Academic ethicists and philosophers
- Military strategists and defense policymakers
- AI researchers and engineers working on autonomous systems

**Secondary:**

- International organizations (UN, NATO)
- Legal scholars specializing in laws of armed conflict
- General educated public interested in AI ethics

---

## Academic Standards

**Paper Type:** Theoretical/normative ethics paper with practical policy implications

**Expected Length:** 6,000-10,000 words

**Format:** LaTeX source files (.tex)

**Citation Style:** APA or Chicago (to be determined)

**Target Venues:**

- Journals: _Ethics and Information Technology_, _AI & Society_, _Journal of Military Ethics_
- Conferences: AIES, FAccT
- Policy outlets: Brookings, CNAS, RAND

---

## Theoretical Foundations

**Key Frameworks to Engage:**

1. **Just War Theory** (jus ad bellum, jus in bello, jus post bellum)
2. **Asimov's Three Laws** (as inspiration and cautionary tale)
3. **International Humanitarian Law** (Geneva Conventions, distinction, proportionality, necessity)
4. **AI Ethics Principles** (transparency, accountability, human oversight)
5. **Responsibility Gap Theory** (Sparrow, Matthias)

**Ethical Traditions:**

- Deontological ethics (duty-based rules)
- Consequentialism (outcomes and harm minimization)
- Virtue ethics (character of decision-makers and systems)

---

## Key Terms & Definitions

**Defensive AI Systems:** Autonomous or semi-autonomous systems designed primarily to protect against attacks (e.g., missile defense, cyberdefense, perimeter security)

**Offensive AI Systems:** Systems designed to project force or conduct attacks

**Levels of Autonomy:**

- **Human-in-the-loop (HITL):** Human makes every engagement decision
- **Human-on-the-loop (HOTL):** Human supervises, can override
- **Fully Autonomous:** System operates independently

**Lethal Autonomous Weapons Systems (LAWS):** Weapons that can select and engage targets without human intervention

---

## Critical Issues to Address

1. **The Responsibility Gap:** Who is accountable when AI makes lethal mistakes?
2. **Speed vs. Ethics:** When machines decide faster than humans can ethically review
3. **Adversarial Dynamics:** What if adversaries don't follow these rules?
4. **Defensive/Offensive Blur:** Many systems can be dual-use
5. **Verification & Enforcement:** How do we ensure compliance?
6. **Cultural/International Perspectives:** Western vs. non-Western ethical frameworks

---

## Scope & Limitations

**In Scope:**

- Ethical principles for military AI in defensive roles
- Human oversight requirements
- Accountability mechanisms
- International law compliance

**Out of Scope:**

- Detailed technical AI implementation
- Specific weapon system designs
- Comprehensive international treaty language
- Non-military AI ethics (though may reference)

**Acknowledged Limitations:**

- Rapidly evolving technology may outpace ethical frameworks
- Implementation challenges may limit practical application
- International consensus is difficult to achieve
- Some tensions between principles may be irresolvable

---

## Success Criteria

1. **Academically Rigorous:** Engages seriously with existing literature and philosophical traditions
2. **Practically Applicable:** Rules can guide actual policy and system design
3. **Intellectually Original:** Contributes something new beyond restating existing principles
4. **Clearly Argued:** Logical structure with well-supported claims
5. **Publication-Ready:** Meets standards for peer-reviewed venues

---

## Related Work to Review

**Foundational:**

- Asimov, I. - _I, Robot_ and Three Laws
- Walzer, M. - _Just and Unjust Wars_
- Geneva Conventions and Additional Protocols

**Contemporary AI Ethics:**

- Russell, S. - _Human Compatible_
- Scharre, P. - _Army of None_
- Amodei, D. et al. - Concrete Problems in AI Safety

**Military/Policy:**

- US DoD AI Ethical Principles
- NATO AI Strategy
- UN Group of Governmental Experts on LAWS reports
- Human Rights Watch - "Losing Humanity" report

**Philosophical:**

- Sparrow, R. - "Killer Robots"
- Matthias, A. - "The Responsibility Gap"
- Asaro, P. - Work on autonomous weapons

---

## Project Status

**Current Phase:** Initial planning and framework development
**Next Steps:** See PLAN.md for detailed roadmap
