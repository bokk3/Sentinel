# Research Notes: Asimov's Three Laws & Military AI (Deep Dive)

**Phase:** 1.1 Literature Review (Advanced)
**Date:** 2025-12-16

## 1. Meta-Ethical Critiques (Susan Leigh Anderson)

- **The Inadequacy of Rules:** Anderson (2008) uses Asimov's _Bicentennial Man_ to argue that rigid rule-based systems (like the Three Laws) inevitably treat intelligent machines as slaves. A truly ethical entity must eventually transcend written rules to act on _principle_.
- **Implication for Sentinel:** This supports our plan to move from "laws" (natural language) to "constraints" (hard-coded limits). We are not trying to create a general moral agent (like Andrew Martin), but a specialized defensive tool. We accept the "slave" designation for the machine to ensure safety.

## 2. Machine Ethics vs. Military Reality

- **The "Correctness" Problem:** Anderson & Anderson argue that we cannot program "correct" ethical behavior until ethicists agree on what that is (which they don't).
- **Military Application:** In warfare, "correct" is defined by IHL and ROE. This makes the military domain _easier_ for AI ethics than general society in one specific way: the rules are codified (Geneva/Hague conventions).

## 3. Updated Sources

- Anderson, S. L. (2008). "Asimovâ€™s 'three laws of robotics' and machine metaethics."
- Anderson, M. & Anderson, S. L. (2007). "Machine Ethics: Creating an Ethical Intelligent Agent."
