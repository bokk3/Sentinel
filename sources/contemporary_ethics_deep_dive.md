# Research Notes: Contemporary AI Ethics (Deep Dive)

**Phase:** 1.1 Literature Review (Advanced)
**Date:** 2025-12-16

## 1. The "Moral Crumple Zone" (Elish)

- **Concept:** Just as a car's physical crumple zone absorbs impact, the human operator in a complex automated system (like an autonomous weapon controller) becomes the "Moral Crumple Zone."
- **The Problem:** When the system fails (the AI kills a civilian), the legal and moral blame "smashes into" the nearest human operator, even if they had no realistic ability to intervene (because the system was opaque or too fast).
- **Implication for Sentinel:** We must _design out_ the Moral Crumple Zone. If the system is strictly autonomous for speed, the operator cannot be blamed for a specific intercept failure. Responsibility must shift to the _Rules of Engagement_ designer (the Commander/Policy Maker).

## 2. Updated Sources

- Elish, M. C. (2019). "Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction."
