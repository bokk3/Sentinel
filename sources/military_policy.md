# Research Notes: Military & International Policy on AI

**Date:** 2025-12-16
**Topic:** US DoD Directive 3000.09, NATO AI Strategy, and UN GGE Guiding Principles.
**Phase:** 1.1 Literature Review

## 1. US DoD Directive 3000.09 (Updated 2023)

- **Core Mandate:** Autonomous and semi-autonomous weapon systems must be designed to allow commanders and operators to exercise **"appropriate levels of human judgment over the use of force."**
- **Key Updates (2023):**
  - Explicitly links to _DoD AI Ethical Principles_.
  - Applies to "armed platforms" (remotely operated or manned).
  - Requires rigorous Testing & Evaluation (T&E) for "emergent behavior."
  - Establishes an _Autonomous Weapon Systems Working Group_.
- **Relevance:** It does _not_ ban autonomous weapons but creates a high barrier of review and emphasizes limiting the "black box" risk via T&E.

## 2. NATO AI Strategy

- **Principles of Responsible Use (PRUs):**
  1.  **Lawfulness:** Compliance with national/international law.
  2.  **Responsibility & Accountability:** Human responsibility must be clear; no transfer of accountability to machines.
  3.  **Explainability & Traceability:** Systems must be understandable and auditable.
  4.  **Reliability:** Defined use cases and resilience.
  5.  **Governability:** Human-machine interaction fostering trust.
  6.  **Bias Mitigation:** Proactive efforts to minimize bias.
- **Goal:** Interoperability among allies while maintaining ethical standards.

## 3. UN GGE on LAWS (11 Guiding Principles)

- **Principle B:** Human responsibility for decisions on the use of weapons systems must be retained since accountability cannot be transferred to machines.
- **Principle C:** Human-machine interaction should ensure compliance with IHL.
- **Principle H:** Human judgment is essential to ensure compliance with IHL.
- **Consensus:** The CCW (Convention on Certain Conventional Weapons) is the appropriate framework.
- **Note:** These are _principles_, not a binding treaty banning LAWS.

## 4. Implications for "I, Sentinel"

- **"Appropriate Judgment":** This phrase from DoD 3000.09 is the loophole/opportunity. For a defensive system, "appropriate judgment" might be delegating the sub-second intercept decision to the AI, provided the _deployment_ decision was human-led.
- **Accountability Chain:** Both NATO and UN emphasize that a human must be blameworthy. Our ruleset must define _who_ that is (Commander vs. Developer).
- **Explainability:** NATO's focus on explainability reinforces the need for our system to log _why_ it acted (the "Black Box" log).

## Sources Reviewed

- DoD Directive 3000.09 (2023 Update)
- NATO AI Strategy Summary
- UN GGE on LAWS Guiding Principles
