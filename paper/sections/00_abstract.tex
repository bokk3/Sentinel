% Abstract
In the era of hypersonic warfare, the human reaction time is functionally obsolete, necessitating the deployment of autonomous defensive systems. However, existing ethical frameworks—from Asimov's Three Laws to current military "Human-in-the-loop" doctrines—fail to provide a robust moral architecture for systems that typically operate in the milliseconds before impact. This paper proposes the "Sentinel" Ruleset: a purely defensive, hierarchical ethical framework designed to govern high-speed autonomous interception. We define five core principles: Defensive Limitation, Distinction \& Certainty, Human Sovereignty (via pre-delegation), Proportional Sacrifice (Machine Martyrdom), and Traceability. Through scenario analysis, we demonstrate that a purely defensive AI must be programmed to "Fail Open"—prioritizing the risk of false negatives (missed intercepts) over the risk of false positives (war crimes)—and must accept its own destruction to spare human life. This framework resolves the tension between operational speed and ethical control, offering a path toward the responsible deployment of AI "Shields."
